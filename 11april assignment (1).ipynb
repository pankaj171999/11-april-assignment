{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea9aeb-18ca-4063-bd85-6d629cf89ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1(Ans)Ensemble methods are techniques that create multiple models and then combine them to produce improved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6e63f7-15ba-49be-9c4f-5526a062ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2(Ans)There are two main reasons to use an ensemble over a single model, and they are related; they are: Performance:\n",
    "An ensemble can make better predictions and achieve better performance than any single contributing model. \n",
    "Robustness: An ensemble reduces the spread or dispersion of the predictions and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d501223-583a-4a6f-a546-c7d00f5da53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3(Ans)Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce variance within a noisy dataset. \n",
    "In bagging, a random sample of data in a training set is selected with replacement—meaning that the individual data points can be chosen more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5c6bc-108f-485a-9115-41f8dd15a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4(Ans)Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. \n",
    "In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to \n",
    "compensate for the weaknesses of its predecessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99cf91-464c-4628-a10a-4a1b08349a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5(Ans)Ensemble methods offer several advantages over single models, such as improved accuracy and performance, especially \n",
    "for complex and noisy problems. They can also reduce the risk of overfitting and underfitting by balancing the trade-off \n",
    "between bias and variance, and by using different subsets and features of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7237e3-6eb7-4df2-be14-1db74cf69c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6(Ans)Yes,an ensemble techniques always better than individual models because Ensemble methods have higher predictive accuracy,\n",
    "compared to the individual models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11baf9-376a-42b2-9c64-b675372f4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7(Ans)Once the standard error is calculated, the confidence interval is determined by multiplying the standard error by a constant that \n",
    "reflects the level of significance desired, based on the normal distribution. The constant for 95 percent confidence intervals is 1.96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca561b81-a8e5-4586-9ad9-d061a716c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8(Ans)Bootstrapping is done by repeatedly sampling (with replacement) the sample dataset to create many simulated samples. \n",
    "Each simulated bootstrap sample is used to calculate an estimate of the parameter,and these estimates are then combined to form a sampling distribution\n",
    "\n",
    "Steps of Bootstrap are \n",
    "* A sample from population with sample size n.\n",
    "* Draw a sample from the original sample data with replacement with size n, and replicate B times, each re-sampled sample is called a Bootstrap Sample, \n",
    "and there will totally B Bootstrap Samples.\n",
    "* Evaluate the statistic of θ for each Bootstrap Sample, and there will be totally B estimates of θ.\n",
    "* Construct a sampling distribution with these B Bootstrap statistics and use it to make further statistical inference, such as:\n",
    "* Estimating the standard error of statistic for θ.\n",
    "* Obtaining a Confidence Interval for θ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8a2d1-7a50-4863-a131-5340644c8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9(Ans) CI = the confidence interval\n",
    "X̄ = the population mean\n",
    "Z* = the critical value of the z distribution\n",
    "σ = the population standard deviation\n",
    "√n = the square root of the population size\n",
    "\n",
    "X̄=15\n",
    "Z*=1.96\n",
    "σ=2 \n",
    "√n =50\n",
    " \n",
    "lower and upper bound of 95% of the confidence interval intervals are is 14.45 to 15.55    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
